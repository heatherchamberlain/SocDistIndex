{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ease of social distancing index v1.0\n",
    "## Notebook 2: calculation of index\n",
    "\n",
    "Code written by Heather Chamberlain\n",
    "\n",
    "This notebook contains the code needed to calculate the ease of social distancing index value for each spatial unit. The spatial units can be created using Notebook 1. \n",
    "\n",
    "Once this Notebook has been run to completion, the output should consist of the ease of social distancing index values calculated for all spatial units, along with contributing built and population density scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "import os\n",
    "import arcpy\n",
    "import glob\n",
    "\n",
    "from arcpy.sa import *\n",
    "arcpy.CheckOutExtension(\"Spatial\")\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup the necessary filepaths and directory structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify country of interest using 3 letter ISO code, and specify path for home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso = \"KEN\"\n",
    "folder_iso = \"XXX\"\n",
    "#e.g. iso = \"SSD\"\n",
    "\n",
    "home_folder = Path(\"SUBSTITUTE/FOLDER/PATH/HERE\")\n",
    "\n",
    "print('ISO code specified: ' + str(iso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset version\n",
    "vers = 'v1_0'\n",
    "\n",
    "#working gdb name\n",
    "gdb_name = str(iso) + \"_working_v1_0_alpha.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_folder = home_folder / folder_iso #path for country folder\n",
    "\n",
    "ssa_folder = home_folder / \"ssa51\" #path for folder with data for all 51 countries in Sub-Saharan Africa\n",
    "\n",
    "data_in_folder = c_folder / \"DataIn\" #path for input data directory for the country of interest\n",
    "w_folder = c_folder / \"Working\" #working directory for the country of interest\n",
    "output_folder = c_folder / \"Output\" #output directory for the country of interest\n",
    "\n",
    "uext_iso_folder = data_in_folder / \"AOIs\"  #path for sub-directory for urban extent (AOI) file \n",
    "adm0_iso_folder = data_in_folder / \"Adm0\"  #path for sub-directory for national boundary file for the country of interest\n",
    "utm_iso_folder = data_in_folder / \"UTMzone_polys\"  #path for sub-directory for UTM zone file\n",
    "\n",
    "bf_root = Path(\"SUBSTITUTE/FOLDER/PATH/HERE\")\n",
    "iso_bf_folder = data_in_folder / \"BuildingFootprints\" #path for sub-directory for additional building footprint files for the country of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdb_path = w_folder / gdb_name\n",
    "if os.path.isdir(str(gdb_path)):\n",
    "    print(\"w_gdb already exists\")\n",
    "else:\n",
    "    print(\"creating w_gdb\")\n",
    "    arcpy.CreateFileGDB_management(str(w_folder), gdb_name) #create gdb\n",
    "w_gdb = w_folder / gdb_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identify the input files needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data needed to calculate the population density and built score values:\n",
    "- Spatial units (created from Notebook 1)\n",
    "- Building footprints (Maxar/Ecopia building footprints were used in calculating the ease of social distancing index v1.0, but other similar datasets could be used in their place where available e.g. Google building footprints, Microsoft building footprints)\n",
    "- WorldPop gridded population datasets\n",
    "- Grid cell surface area dataset (providing area of each grid cell in the WP gridded pop datasets)\n",
    "\n",
    "Other files required in processing data:\n",
    "- UTM zones\n",
    "- Urban extents (AOIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data needed to calculate the population density and built score values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First identify the UTM zones in which the spatial units are located - 1 file per UTM zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing = glob.glob(str(utm_iso_folder) + \"/**/UTMzone_*.shp\", recursive = True)\n",
    "\n",
    "utm_zones_list = []\n",
    "\n",
    "for filename in listing:\n",
    "    u = (Path(filename).stem).split(\"_\")[1]\n",
    "    utm_zones_list.append(u)   \n",
    "    \n",
    "s_count = len(utm_zones_list)\n",
    "\n",
    "print(\"for \" + str(iso) + \" the spatial units are split across \" + str(s_count) + \" UTM zones: \" + str(utm_zones_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_units = []\n",
    "\n",
    "for zone in utm_zones_list:\n",
    "    area_polys_elimf = str(w_gdb / (\"area_polys_elimf_UTM\" + str(zone)))\n",
    "    spatial_units.append(area_polys_elimf)\n",
    "    \n",
    "print(spatial_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building footprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building footprints\n",
    "bf_path = bf_root / iso #for one country, different datasets for different UTM zones.\n",
    "\n",
    "blist = []\n",
    "\n",
    "bf_gdb = glob.glob(str(bf_path) + \"/**/*.gdb\", recursive = True)\n",
    "folder = Path(bf_gdb[0]).parent\n",
    "\n",
    "for file in os.listdir(folder):\n",
    "    if fnmatch.fnmatch(file, '*.shp'):\n",
    "        blist.append(str(folder / file))\n",
    "        #print(file) \n",
    "                     \n",
    "print(blist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Population rasters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pop_raster \n",
    "pop_path = home_folder / iso / \"DataIn\" / \"PopRaster\" #pop raster for one country.\n",
    "    \n",
    "popbu_list = ['ZMB', 'NGA', 'SLE', 'MOZ', 'SSD', 'GHA', 'COD', 'BFA'] #list of iso codes for countries with bottom-up pop datasets/alternatives to the global constrained datasets\n",
    "\n",
    "#different file names for top-down and bottom-up datasets. Use if statement to get appropriate name format\n",
    "if iso.upper() in popbu_list:\n",
    "    for file in os.listdir(pop_path):\n",
    "        if fnmatch.fnmatch(file, '*gridded.tif'):\n",
    "            pop_file_name = file\n",
    "            pop_raster = str(pop_path / pop_file_name)\n",
    "            print('bottom up pop dataset: {}'.format(pop_raster))\n",
    "        elif fnmatch.fnmatch(file, '*gridded_population.tif'):\n",
    "            pop_file_name = file\n",
    "            pop_raster = str(pop_path / pop_file_name)\n",
    "            print('bottom up pop dataset: {}'.format(pop_raster))\n",
    "else:\n",
    "    pop_file_name = str(iso.lower()) + \"_ppp_2020_constrained.tif\"\n",
    "    pop_raster = str(pop_path / pop_file_name)\n",
    "    print('top down constrained pop dataset: {}'.format(pop_raster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid cell surface area raster (used in converting pop count to density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid cell surface area dataset\n",
    "px_file_name = str(iso.lower()) + \"_px_area_100m.tif\"\n",
    "px_area_raster = str(pop_path / px_file_name)\n",
    "print('px area raster: {}'.format(px_area_raster))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other files required in processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban extent polygons (clipped to adm0 boundary)\n",
    "uext_poly = str(uext_iso_folder / (\"uext_polys_\" + str(iso) + \"_adm0.shp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utm zone boundaries\n",
    "utm_folder = home_folder / \"UTM\"\n",
    "utm_zones = str(utm_folder / \"UTM_zones_all.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prepare the input files needed for calculating the population density and built score values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip building footprints to urban extents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip bfs to uext\n",
    "clip_area = str(uext_poly)\n",
    "        \n",
    "for file in blist:    \n",
    "    data_in = file\n",
    "    #print(data_in)\n",
    "    data_out = str(w_gdb / Path(file).stem) + \"_AOIclip\"\n",
    "    #print(data_out)\n",
    "    \n",
    "    if arcpy.Exists(data_out):\n",
    "        print(\"file already exists - skipped in terms of clipping\")\n",
    "        #repair geometery of file\n",
    "        #arcpy.management.RepairGeometry(data_out, \"DELETE_NULL\", \"ESRI\")\n",
    "        arcpy.management.RepairGeometry(data_out, \"DELETE_NULL\", \"OGC\")\n",
    "        \n",
    "        print(\"repair geometery run\")\n",
    "    else:\n",
    "        print(\"clipping\")\n",
    "        arcpy.analysis.Clip(data_in, clip_area, data_out, None)\n",
    "        #repair geometery of file\n",
    "        #arcpy.management.RepairGeometry(data_out, \"DELETE_NULL\", \"ESRI\")\n",
    "        arcpy.management.RepairGeometry(data_out, \"DELETE_NULL\", \"OGC\")\n",
    "        \n",
    "        print(\"repair geometery run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.env.workspace = str(w_gdb)\n",
    "\n",
    "for zone in utm_zones_list:\n",
    "    print(zone)\n",
    "    \n",
    "    #define inputs\n",
    "    area_polys_elimf = str(w_gdb / (\"area_polys_elimf_UTM\" + str(zone))) #area polygons (output from eliminate)\n",
    "    \n",
    "    #file name UTM zone number is preceded by a 6 if N and 7 is S, determine this ready for list expression\n",
    "    s_n = zone[-1]\n",
    "    if s_n is 'N':\n",
    "        zone_n = '6'    \n",
    "    elif s_n is 'S':\n",
    "        zone_n = '7'\n",
    "    \n",
    "    #find all clipped bf files for the country for the specified UTM zone\n",
    "    expression = \"*building*\" + str(zone_n) + str(zone[:2]) + \"*AOIclip\"\n",
    "    \n",
    "    multifile_list = []\n",
    "    for file in arcpy.ListFeatureClasses(expression): #find all files matching expression (UTM zone) \n",
    "        multifile_list.append(file) #and append to list\n",
    "        \n",
    "    print(multifile_list)\n",
    "    \n",
    "    if len(multifile_list) > 1: #if list has more than one item, i.e. there is more than one file for the utm zone, then merge\n",
    "        print(\"there are multiple bf files per UTM zones - files need merging\")\n",
    "    else:\n",
    "        print(\"only one bf file per UTM zones - no prior merging needed\")\n",
    "        bf_UTMzone = str(w_gdb / file)\n",
    "        print(bf_UTMzone)\n",
    "    \n",
    "    ####\n",
    "    #for the subset of polygons in each utm zone, check which utm zone polygons they overlap with (select by location)\n",
    "    ####\n",
    "    area_polys_subset = str(w_gdb / (str(iso) + \"_area_polys_span_utm_zone_\" + str(zone)))\n",
    "    \n",
    "    bf_extra_list = []\n",
    "    \n",
    "    if arcpy.Exists(area_polys_subset):\n",
    "        print(\"area_polys_subset exists\")\n",
    "    \n",
    "        #from the subset of area polygons, check which utm zone polygons they overlap with (select by location)\n",
    "        utm_zones_shp = str(utmzones_folder / \"utm_zones_lyr.shp\")\n",
    "        area_polys_subset_lyr = arcpy.MakeFeatureLayer_management(area_polys_subset, \"area_polys_subset_lyr\")\n",
    "        utm_zones_span = arcpy.management.SelectLayerByLocation(utm_zones_shp, \"CROSSED_BY_THE_OUTLINE_OF\", area_polys_subset_lyr, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "        #add the UTM zone ID for the selected zones to a list\n",
    "        utm_check_list = []\n",
    "        with arcpy.da.SearchCursor(utm_zones_span, 'utm_zone') as cursor:\n",
    "            for row in cursor:\n",
    "                utm_check_list.append(row[0])        \n",
    "        print(utm_check_list)\n",
    "\n",
    "        #if length of list is >1, select the building footprint polygons from any additional utm zones\n",
    "        if len(utm_check_list) > 1:\n",
    "            utm_neighbour_list = utm_check_list\n",
    "            utm_neighbour_list.remove(zone) #remove current zone from list\n",
    "\n",
    "            #for remaining utm zones, \n",
    "            for item in utm_neighbour_list:\n",
    "                print('item: {}'.format(item))\n",
    "                \n",
    "                #file name UTM zone number is preceded by a 6 if N and 7 is S, determine this ready for list expression\n",
    "                s_n = item[-1]\n",
    "                if s_n is 'N':\n",
    "                    zone_n = '6'    \n",
    "                elif s_n is 'S':\n",
    "                    zone_n = '7'\n",
    "                \n",
    "                #find all clipped bf files for the country for the specified UTM zone\n",
    "                expression = \"*building*\" + str(zone_n) + str(item[:2]) + \"*AOIclip\"\n",
    "                \n",
    "                for file in arcpy.ListFeatureClasses(expression): #find all files matching expression (UTM zone) \n",
    "                    #building footprint file\n",
    "                    bf_file = file\n",
    "                    print(file)\n",
    "                        \n",
    "                    #select any building footprints that are within subsetted area polygons\n",
    "                    bf_sel = arcpy.management.SelectLayerByLocation(bf_file, \"HAVE_THEIR_CENTER_IN\", area_polys_subset, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "                    \n",
    "                    n_selected = int(arcpy.GetCount_management(bf_sel)[0])\n",
    "                    print('n_selected = {}'.format(n_selected))\n",
    "                \n",
    "                    #write out selected building footprints (those within one UTM zone but associated with area polygons from neighbour)\n",
    "                    bf_subset = str(w_gdb / (str(iso) + \"_bf_polys_from_utm_zone_\" + str(item) + \"_to_add_to_UTM_zone_\" + str(zone)))\n",
    "                    arcpy.CopyFeatures_management(bf_sel, bf_subset, '', None, None, None)\n",
    "                    \n",
    "                    bf_extra_list.append(bf_subset)\n",
    "    \n",
    "    ################\n",
    "    #add in any building footprints from \"neighbours\" (due to different adm0 boundaries)\n",
    "    #find the relevant (pre-processed) files and append to bf_extra_list\n",
    "    for file_x in os.listdir(iso_bf_folder):\n",
    "        \n",
    "        #file name UTM zone number is preceded by a 6 if N and 7 is S, determine this ready for list expression\n",
    "        s_n = zone[-1]\n",
    "        if s_n is 'N':\n",
    "            zone_n = '6'    \n",
    "        elif s_n is 'S':\n",
    "            zone_n = '7'\n",
    "        \n",
    "        expression = str(iso.upper()) + \"*\" + str(zone_n) + str(zone[:2]) + \"_*shp\"\n",
    "        if fnmatch.fnmatch(file_x, expression):\n",
    "            file_x_fc = str(w_gdb / (str(file_x[:-4])))\n",
    "            arcpy.CopyFeatures_management(str(iso_bf_folder / file_x), file_x_fc, '', None, None, None)\n",
    "            \n",
    "            bf_extra_list.append(file_x_fc)\n",
    "            print(\"BFs from neighbouring country dataset added: {}\".format(file_x_fc))      \n",
    "\n",
    "    ################\n",
    "    \n",
    "    #print(bf_extra_list)\n",
    "    if len(bf_extra_list) > 0: #merge all additional building footprints\n",
    "        print('length of bf_extra_list > 0: {}'.format(bf_extra_list))\n",
    "                \n",
    "        #file name UTM zone number is preceded by a 6 if N and 7 is S, determine this ready for list expression\n",
    "        s_n = zone[-1] \n",
    "        if s_n is 'N':\n",
    "            zone_n = '6'    \n",
    "        elif s_n is 'S':\n",
    "            zone_n = '7'\n",
    "                \n",
    "        #find all clipped bf files for the country for the specified UTM zone\n",
    "        expression = \"*building*\" + str(zone_n) + str(zone[:2]) + \"*AOIclip\"\n",
    "                \n",
    "        for file in arcpy.ListFeatureClasses(expression): #find all files matching expression (UTM zone) \n",
    "            #building footprint file\n",
    "            bf_file = file\n",
    "        \n",
    "            bf_extra_list.append(bf_file)\n",
    "            arcpy.management.SelectLayerByAttribute(bf_file, \"CLEAR_SELECTION\", '', None) #clear previous selection\n",
    "        \n",
    "        #n_selected = int(arcpy.GetCount_management(bf_file)[0])\n",
    "        #print('n_selected = {}'.format(n_selected))\n",
    "        \n",
    "        bf_UTMzone = str(bf_file) + \"_w_extras\"\n",
    "        z = arcpy.management.Merge(bf_extra_list, bf_UTMzone)\n",
    "        \n",
    "        #n_selected = int(arcpy.GetCount_management(z)[0])\n",
    "        #print('n_selected = {}'.format(n_selected))\n",
    "    \n",
    "    print( )\n",
    "    \n",
    "    intersect_list = [area_polys_elimf, bf_UTMzone] #list of features to intersect\n",
    "    \n",
    "    intersect_output = str(w_gdb / (\"bf_\" + str(zone) + \"_area_polys_INTERSECT\"))\n",
    "    \n",
    "    print(intersect_output)\n",
    "    \n",
    "    arcpy.analysis.Intersect(intersect_list, intersect_output, \"ALL\", None, \"INPUT\") #run intersect tool\n",
    "    \n",
    "    \n",
    "    # Set output coordinate system\n",
    "    utm_id = 'WGS 1984 UTM Zone ' + str(zone)\n",
    "    #print(utm_id)\n",
    "    outCS = arcpy.SpatialReference(utm_id)\n",
    "    \n",
    "    #calculate building footprint area\n",
    "    arcpy.management.CalculateGeometryAttributes(intersect_output, \"POLY_AREA AREA\", '', \"SQUARE_METERS\", outCS, \"SAME_AS_INPUT\")                           \n",
    "    \n",
    "    print( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate the area of building footprints to account for those that have been split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in utm_zones_list:\n",
    "    \n",
    "    # Set output coordinate system\n",
    "    utm_id = 'WGS 1984 UTM Zone ' + str(zone)\n",
    "    print(utm_id)\n",
    "    outCS = arcpy.SpatialReference(utm_id)\n",
    "    \n",
    "    #specify dataset to calculate polygon area for and run tool\n",
    "    intersect_output = str(w_gdb / (\"bf_\" + str(zone) + \"_area_polys_INTERSECT\"))\n",
    "    print(intersect_output)\n",
    "    arcpy.management.CalculateGeometryAttributes(intersect_output, \"POLY_AREA AREA\", '', \"SQUARE_METERS\", outCS, \"SAME_AS_INPUT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. For each spatial unit, calculate the population density and proportion of area built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the total building area within each polygon (spatial join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in utm_zones_list:\n",
    "    \n",
    "    area_polys_elimf = str(w_gdb / (\"area_polys_elimf_UTM\" + str(zone))) #area polygons (output from eliminate)\n",
    "    intersect_output = str(w_gdb / (\"bf_\" + str(zone) + \"_area_polys_INTERSECT\")) #intersected building footprints\n",
    "    \n",
    "    targetFeatures = area_polys_elimf\n",
    "    joinFeatures = intersect_output \n",
    "    out_feature_class = str(w_gdb / (\"area_polys_bfareaSUM_UTM\" + str(zone)))\n",
    "    \n",
    "    # Create a new fieldmappings and add the two input feature classes.\n",
    "    fieldmappings = arcpy.FieldMappings()\n",
    "    fieldmappings.addTable(targetFeatures)\n",
    "    fieldmappings.addTable(joinFeatures)\n",
    "    \n",
    "    # Create new fieldmaps (1 for each output field required)\n",
    "    fldmap_POLY_AREA_1 = arcpy.FieldMap()\n",
    "    \n",
    "    fldmap_POLY_AREA_1.addInputField(joinFeatures, \"POLY_AREA\") #does this need to be POLY_AREA1?\n",
    "    \n",
    "    # Set the merge rule to find the summed value of all bf in each feature\n",
    "    fldmap_POLY_AREA_1.mergeRule = 'SUM'\n",
    "    \n",
    "    #set name\n",
    "    f_name = fldmap_POLY_AREA_1.outputField\n",
    "    f_name.name = 'SUM_POLY_AREA'\n",
    "    f_name.aliasName = 'SUM_POLY_AREA'\n",
    "    fldmap_POLY_AREA_1.outputField = f_name\n",
    "    \n",
    "    #Add all FieldMaps to the FieldMappings Object\n",
    "    fieldmappings.addFieldMap(fldmap_POLY_AREA_1)\n",
    "    \n",
    "    #spatial join with summing of bf poly area    \n",
    "    arcpy.analysis.SpatialJoin(targetFeatures, joinFeatures, out_feature_class, \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", fieldmappings, \"CONTAINS\", None, '')\n",
    "    print(out_feature_class)\n",
    "    \n",
    "    #change null values in SUM_POLY_AREA field to 0s\n",
    "    field = 'SUM_POLY_AREA'\n",
    "    with arcpy.da.UpdateCursor(out_feature_class, field) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == None:\n",
    "                row[0] = 0\n",
    "                \n",
    "            cursor.updateRow(row) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the necessary fields (proportion built, proportion not built etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in utm_zones_list:\n",
    "    area_units = str(w_gdb / (\"area_polys_bfareaSUM_UTM\" + str(zone)))\n",
    "    \n",
    "    #calc proportion of polygon occupied by built structures\n",
    "    arcpy.management.CalculateField(area_units, \"BUILT_PROP\", \"!SUM_POLY_AREA!/!POLY_AREA!\", \"PYTHON3\", '', \"FLOAT\")\n",
    "    \n",
    "    #calc proportion of polygon not occupied by built structures\n",
    "    arcpy.management.CalculateField(area_units, \"NBUILTPROP\", \"1-(!SUM_POLY_AREA!/!POLY_AREA!)\", \"PYTHON3\", '', \"FLOAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change projection to WGS84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zone in utm_zones_list:\n",
    "    \n",
    "    area_units = str(w_gdb / (\"area_polys_bfareaSUM_UTM\" + str(zone)))\n",
    "    area_units_WGS84 = str(area_units) + \"_WGS84\"\n",
    "    \n",
    "    # Set output coordinate system to WGS84\n",
    "    outCS = arcpy.SpatialReference(4326)\n",
    "    \n",
    "    # run project tool\n",
    "    arcpy.Project_management(area_units, area_units_WGS84, outCS)\n",
    "    print(area_units_WGS84)\n",
    "\n",
    "#NOTE: alias for new file doesn't update to file name when project is run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge spatial units from each UTM zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_list = []\n",
    "\n",
    "for zone in utm_zones_list:\n",
    "    area_units_WGS84 = str(w_gdb / (\"area_polys_bfareaSUM_UTM\" + str(zone))) + \"_WGS84\"\n",
    "    merge_list.append(area_units_WGS84)\n",
    "\n",
    "#merge polygon datasets in list\n",
    "merged_output = str(w_gdb / (str(iso) + \"_\" + str((Path(area_units_WGS84).stem)[:-12]) + \"WGS84\"))\n",
    "arcpy.management.Merge(merge_list, merged_output)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pop density raster from pop count and raster of grid cell area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dens_null_raster = str(w_gdb / (str(iso) + \"_pop_density_null\")) \n",
    "\n",
    "outDivide = arcpy.sa.Divide(pop_raster, px_area_raster) #divide pop count by grid cell area\n",
    "outDivide.save(pop_dens_null_raster)\n",
    "\n",
    "#px_area units is m2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert null grid cell values to 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dens_zero_raster = str(w_gdb / (str(iso) + \"_pop_density_zero\")) \n",
    "\n",
    "output_raster = arcpy.sa.Con(arcpy.sa.IsNull(pop_dens_null_raster), 0, pop_dens_null_raster)\n",
    "output_raster.save(pop_dens_zero_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert pop density raster from pop per sqm to per sqkm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_dens_sqkm_zero_raster = str(w_gdb / (str(iso) + \"_pop_density_sqkm_zero\")) \n",
    "\n",
    "popsqkm_raster = Raster(pop_dens_zero_raster) * 1000000\n",
    "popsqkm_raster.save(pop_dens_sqkm_zero_raster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate average pop density within each spatial unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create UID field\n",
    "arcpy.management.CalculateField(merged_output, \"UID\", \"!OBJECTID!\", \"PYTHON3\", '', \"TEXT\")\n",
    "\n",
    "#zonal statistics as table - MEAN\n",
    "zs_table = str(w_gdb / (str(iso) + \"_zs_mean_pop_density\"))\n",
    "arcpy.sa.ZonalStatisticsAsTable(merged_output, \"UID\", pop_dens_sqkm_zero_raster, zs_table, \"DATA\", \"MEAN\", \"CURRENT_SLICE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for spatial units with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get count of number of polys for which zonal statistics calculated\n",
    "zs_count = int(arcpy.GetCount_management(zs_table)[0]) \n",
    "total_poly_count = int(arcpy.GetCount_management(merged_output)[0]) \n",
    "print(\"In total, there are {} unit polygons, of which {} were recognised as zones in calculating mean pop density\".format(zs_count, total_poly_count))\n",
    "print(\"Therefore there are {} unit polygons for which mean pop density has not been calculated\".format(str(total_poly_count-zs_count)))\n",
    "\n",
    "#add new field for mean pop density\n",
    "mean_pop_dens_field = \"POP_DENS\"\n",
    "arcpy.AddField_management(merged_output, mean_pop_dens_field, \"DOUBLE\")\n",
    "\n",
    "#join based on UID\n",
    "in_field = \"UID\"\n",
    "join_field = \"UID\"\n",
    "zs_join = arcpy.AddJoin_management(merged_output, in_field, zs_table, join_field)\n",
    "\n",
    "#update mean pop density field with calculated values\n",
    "calc_expression = \"!\" + str(Path(zs_table).stem) + \".MEAN!\"\n",
    "arcpy.management.CalculateField(zs_join, mean_pop_dens_field, calc_expression, \"PYTHON3\", '', \"FLOAT\")\n",
    "\n",
    "#remove join and write out to file\n",
    "arcpy.RemoveJoin_management(zs_join)\n",
    "\n",
    "zs_join_out = str(merged_output + '_zsjoin')\n",
    "arcpy.CopyFeatures_management(zs_join, zs_join_out)\n",
    "\n",
    "#select records where UID is null, i.e. no values calculated\n",
    "expression = str(mean_pop_dens_field) + \" IS NULL\"\n",
    "selected = arcpy.management.SelectLayerByAttribute(zs_join_out, \"NEW_SELECTION\", expression, None) \n",
    "zs_missing_count = int(arcpy.GetCount_management(selected)[0])\n",
    "print(\"After joining, there are {} unit polygons for which mean pop density has not been calculated\".format(str(total_poly_count-zs_count)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean pop density values for all spatial units with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create centroids (point features) for each polygon\n",
    "out_pts = str(w_gdb / \"zs_missing_pnts\")\n",
    "arcpy.FeatureToPoint_management(selected, out_pts, \"INSIDE\")\n",
    "\n",
    "#extract values to points\n",
    "pts_values = str(w_gdb / \"zs_missing_pnts_values\")\n",
    "arcpy.sa.ExtractValuesToPoints(out_pts, pop_dens_sqkm_zero_raster, pts_values, \"INTERPOLATE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join values (calculated for centroid points) to spatial units and write out to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join point values based on UID\n",
    "in_field = \"UID\"\n",
    "join_field = \"UID\"\n",
    "extvals_join = arcpy.AddJoin_management(zs_join_out, in_field, pts_values, join_field)\n",
    "\n",
    "#update mean pop density field with calculated values, first selecting just the null value to update\n",
    "expression = str(Path(zs_join_out).stem) + \".\" + str(mean_pop_dens_field) + \" IS NULL\"\n",
    "selected = arcpy.management.SelectLayerByAttribute(extvals_join, \"NEW_SELECTION\", expression, None) \n",
    "count = int(arcpy.GetCount_management(selected)[0])\n",
    "print(count)\n",
    "\n",
    "calc_expression = \"!\" + str(Path(pts_values).stem) + \".RASTERVALU!\"\n",
    "arcpy.management.CalculateField(extvals_join, mean_pop_dens_field, calc_expression, \"PYTHON3\", '', \"FLOAT\")\n",
    "\n",
    "#clear selection, remove join and write out to file\n",
    "arcpy.SelectLayerByAttribute_management(extvals_join, \"CLEAR_SELECTION\")\n",
    "arcpy.RemoveJoin_management(extvals_join)\n",
    "\n",
    "polys_calc_out = str(merged_output + '_popdens')\n",
    "arcpy.CopyFeatures_management(extvals_join, polys_calc_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classify the population density and built values, and calculate index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add classification field - classify population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify mean pop density values\n",
    "\n",
    "in_table = polys_calc_out\n",
    "field = \"BUILTscore\"\n",
    "expression = \"reclass_nbuilt(!NBUILTPROP!)\"\n",
    "expression_type = \"PYTHON3\"\n",
    "field_type = \"SHORT\"\n",
    "codeblock = \"\"\"\n",
    "def reclass_nbuilt(nbuilt):\n",
    "    if nbuilt == 1.0:\n",
    "        return 0\n",
    "    elif nbuilt >= 0.9 and nbuilt <1.0:\n",
    "        return 1\n",
    "    elif nbuilt >= 0.8 and nbuilt < 0.9:\n",
    "        return 2\n",
    "    elif nbuilt >= 0.7 and nbuilt < 0.8:\n",
    "        return 3\n",
    "    elif nbuilt >= 0.6 and nbuilt < 0.7:\n",
    "        return 4\n",
    "    elif nbuilt >= 0.5 and nbuilt < 0.6:\n",
    "        return 5\n",
    "    elif nbuilt >= 0.4 and nbuilt < 0.5:\n",
    "        return 6\n",
    "    elif nbuilt >= 0.3 and nbuilt < 0.4:\n",
    "        return 7\n",
    "    elif nbuilt >= 0.2 and nbuilt < 0.3:\n",
    "        return 8\n",
    "    elif nbuilt >= 0.1 and nbuilt < 0.2:\n",
    "        return 9\n",
    "    elif nbuilt < 0.1:\n",
    "        return 10\"\"\"\n",
    "\n",
    "arcpy.CalculateField_management(in_table, field, expression, expression_type, codeblock, field_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add classification field - classify built proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify non-built area values\n",
    "\n",
    "in_table = polys_calc_out\n",
    "field = \"POPscore\"\n",
    "expression = \"reclass_popdens(!POP_DENS!)\"\n",
    "expression_type = \"PYTHON3\"\n",
    "field_type = \"SHORT\"\n",
    "codeblock = \"\"\"\n",
    "def reclass_popdens(pop_dens):\n",
    "    if pop_dens > 32075.01:\n",
    "        return 10\n",
    "    elif pop_dens > 18042.20 and pop_dens <= 32075.01:\n",
    "        return 9\n",
    "    elif pop_dens > 11547.01 and pop_dens <= 18042.20:\n",
    "        return 8\n",
    "    elif pop_dens > 8018.75 and pop_dens <= 11547.01:\n",
    "        return 7\n",
    "    elif pop_dens > 5891.33 and pop_dens <= 8018.75:\n",
    "        return 6\n",
    "    elif pop_dens > 4510.55 and pop_dens <= 5891.33:\n",
    "        return 5\n",
    "    elif pop_dens > 3563.89 and pop_dens <= 4510.55:\n",
    "        return 4\n",
    "    elif pop_dens > 2886.75 and pop_dens <= 3563.89:\n",
    "        return 3\n",
    "    elif pop_dens > 2385.74 and pop_dens <= 2886.75:\n",
    "        return 2\n",
    "    elif pop_dens > 0.0 and pop_dens <= 2385.74:\n",
    "        return 1\n",
    "    elif pop_dens == 0.0:\n",
    "        return 0\"\"\"\n",
    "\n",
    "arcpy.CalculateField_management(in_table, field, expression, expression_type, codeblock, field_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate index values as the mean of pop and built scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_table = polys_calc_out\n",
    "field = \"INDEXvalue\"\n",
    "expression = \"0.5*(!POPscore! + !BUILTscore!)\"\n",
    "field_type = \"DOUBLE\"\n",
    "\n",
    "arcpy.CalculateField_management(in_table, field, expression, None, None, field_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all areas where grid cells with pop are missing from the constrained raster - set pop density and index score to be NoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all spatial units which contain building footprints from neighbouring country dataset (and are therefore missing pop estimates)\n",
    "expression = str(iso.upper()) + \"_to_add_to_*copy\"\n",
    "file_list = []\n",
    "\n",
    "for file in arcpy.ListFeatureClasses(expression): \n",
    "    file_list.append(file)\n",
    "\n",
    "if len(file_list) > 0:\n",
    "    select_a = arcpy.management.SelectLayerByLocation(polys_calc_out, \"CONTAINS\", file, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "    for file in file_list:\n",
    "        select_b = arcpy.management.SelectLayerByLocation(select_a, \"CONTAINS\", file, None, \"ADD_TO_SELECTION\", \"NOT_INVERT\")\n",
    "    \n",
    "    #set pop density score to NoData value\n",
    "    in_table = select_b\n",
    "    field = \"POPscore\"\n",
    "    expression = \"-99\"\n",
    "\n",
    "    arcpy.CalculateField_management(in_table, field, expression, None, None)\n",
    "\n",
    "\n",
    "    #set index score to NoData value\n",
    "    in_table = select_b\n",
    "    field = \"INDEXvalue\"\n",
    "    expression = \"-99\"\n",
    "\n",
    "    arcpy.CalculateField_management(in_table, field, expression, None, None)\n",
    "\n",
    "\n",
    "if len(file_list) > 0:\n",
    "    #clear existing selection\n",
    "    out = arcpy.SelectLayerByAttribute_management(select_b, \"CLEAR_SELECTION\")\n",
    "else:\n",
    "    out = arcpy.SelectLayerByAttribute_management(polys_calc_out, \"CLEAR_SELECTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Post-processing - formatting of outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update field name for polygon area (UNIT_AREA)\n",
    "field = \"POLY_AREA\"\n",
    "new_field_name = \"UNIT_AREA\"\n",
    "arcpy.management.AlterField(out, field, new_field_name)\n",
    "\n",
    "#update field name for sum_poly_area (BUILT_AREA)\n",
    "field = \"SUM_POLY_AREA\"\n",
    "new_field_name = \"BUILT_AREA\"\n",
    "arcpy.management.AlterField(out, field, new_field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_list_del = []\n",
    "\n",
    "#list all fields. Except for specified fields, add field name to list of fields to be deleted\n",
    "fields = arcpy.ListFields(out)\n",
    "for field in fields:\n",
    "    if field.name == \"OBJECTID\":\n",
    "        print(\"{} is not deletable\". format(field.name))\n",
    "    elif field.name == \"Shape\":\n",
    "        print(\"{} is not deletable\". format(field.name))\n",
    "    elif field.name == \"Shape_Area\":\n",
    "        print(\"{} is not deletable\". format(field.name))\n",
    "    elif field.name == \"Shape_Length\":\n",
    "        print(\"{} is not deletable\". format(field.name))\n",
    "    elif field.name == \"uext_ID\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"adm0_ISO3\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"BUILT_PROP\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"NBUILTPROP\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"POP_DENS\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"BUILTscore\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"POPscore\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"INDEXvalue\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"UNIT_AREA\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    elif field.name == \"BUILT_AREA\":\n",
    "        print(\"{} - keep\". format(field.name))\n",
    "    else:\n",
    "        field_list_del.append(field.name) #append field to list\n",
    "\n",
    "print(\"There are {} fields to be deleted\".format(len(field_list_del)))\n",
    "if len(field_list_del) > 0:\n",
    "    arcpy.DeleteField_management(out, field_list_del) #delete fields\n",
    "    \n",
    "fields = arcpy.ListFields(out)\n",
    "print(\"Final fields:\")\n",
    "for field in fields:\n",
    "    print(\"{0} is a type of {1} with a length of {2}\".format(field.name, field.type, field.length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove polygons where total number of spatial units within uext (for the country of interest) is less than or equal to 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of uext_ID values\n",
    "uextid_list = []\n",
    "\n",
    "with arcpy.da.SearchCursor(uext_poly, 'uext_ID') as cursor:\n",
    "    for row in cursor:\n",
    "        uextid_list.append(row[0])\n",
    "        \n",
    "uextid_del_list = []\n",
    "#for each uext_ID value in the list, calculate the number of spatial units associated with that urban extent\n",
    "for value in uextid_list:\n",
    "    expression = \"uext_ID = \" + str(value)\n",
    "    selected = arcpy.management.SelectLayerByAttribute(out, \"NEW_SELECTION\", expression, None) \n",
    "    count = int(arcpy.GetCount_management(selected)[0])\n",
    "    #print(count)\n",
    "    if count <= 30:\n",
    "        uextid_del_list.append(value)\n",
    "\n",
    "print(uextid_del_list)\n",
    "#Delete the polygons associated with specified uextIDs in uextid_del_list\n",
    "if len(uextid_del_list) > 0:\n",
    "    for value in uextid_del_list:\n",
    "        expression = \"uext_ID = \" + str(value)\n",
    "        out_a = arcpy.management.SelectLayerByAttribute(out, \"NEW_SELECTION\", expression, None) \n",
    "        arcpy.DeleteFeatures_management(out_a)\n",
    "else:\n",
    "    out_a = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcpy.SelectLayerByAttribute_management(out_a, \"CLEAR_SELECTION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out ease of social distancing index output to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#geodatabase version\n",
    "file_out_fc = str(w_gdb / (str(iso.upper()) + \"_ease_of_social_distancing_index_\" + str(vers) + \"_polygons\"))\n",
    "arcpy.CopyFeatures_management(out_a, file_out_fc)\n",
    "\n",
    "#shapefile\n",
    "file_out_shp = str(output_folder / (str(iso.upper()) + \"_SocialDistancing_\" + str(vers) + \"_index.shp\"))\n",
    "arcpy.CopyFeatures_management(out_a, file_out_shp) \n",
    "\n",
    "field_list_del_shp = [\"Shape_Area\", \"Shape_Leng\"] #fields to delete\n",
    "arcpy.DeleteField_management(file_out_shp, field_list_del_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create output point and polygon extent files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban area polys\n",
    "in_features = file_out_shp\n",
    "out_file = str(output_folder / (str(iso.upper()) + \"_SocialDistancing_\" + str(vers) + \"_urban_extents.shp\"))\n",
    "dissolve_field = \"uext_ID\"\n",
    "\n",
    "arcpy.management.Dissolve(in_features, out_file, dissolve_field)\n",
    "\n",
    "field = \"adm0_ISO3\"\n",
    "expression = \"str(iso)\"\n",
    "field_type = \"TEXT\"\n",
    "\n",
    "arcpy.CalculateField_management(out_file, field, expression, None, None, field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#urban area names - select those within output urban area polys\n",
    "uext_pnts = str(uext_iso_folder / (\"ucdb_pts_SSA51_\" + str(iso) + \".shp\"))\n",
    "select_pnts = arcpy.management.SelectLayerByLocation(uext_pnts, \"WITHIN\", out_file, None, \"NEW_SELECTION\", \"NOT_INVERT\")\n",
    "\n",
    "#write selected points to temp file\n",
    "file = str(w_gdb / \"urb_pnts_tmp\")\n",
    "arcpy.CopyFeatures_management(select_pnts, file)\n",
    "\n",
    "#update field name lat (GCPNT_LAT)\n",
    "field = \"GCPNT_LAT\"\n",
    "new_field_name = \"PNT_LAT\"\n",
    "a = arcpy.management.AlterField(file, field, new_field_name, new_field_name)\n",
    "\n",
    "#update field name lon (GCPNT_LON)\n",
    "field = \"GCPNT_LON\"\n",
    "new_field_name = \"PNT_LON\"\n",
    "b = arcpy.management.AlterField(a, field, new_field_name, new_field_name)\n",
    "\n",
    "#update field name country name (CTR_MN_NM)\n",
    "field = \"CTR_MN_NM\"\n",
    "new_field_name = \"adm0_NAME\"\n",
    "c = arcpy.management.AlterField(b, field, new_field_name, new_field_name)\n",
    "\n",
    "#update field name urban centre name (UC_NM_MN)\n",
    "field = \"UC_NM_MN\"\n",
    "new_field_name = \"urb_NAME\"\n",
    "d = arcpy.management.AlterField(c, field, new_field_name, new_field_name)\n",
    "\n",
    "field = \"adm0_ISO3\"\n",
    "expression = \"str(iso)\"\n",
    "field_type = \"TEXT\"\n",
    "\n",
    "e = arcpy.CalculateField_management(d, field, expression, None, None, field_type)\n",
    "  \n",
    "#write out to file\n",
    "out_pnts_shp = str(output_folder / (str(iso.upper()) + \"_SocialDistancing_\" + str(vers) + \"_urban_points.shp\"))\n",
    "arcpy.CopyFeatures_management(e, out_pnts_shp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this notebook has been run to completion, there will be 3 output files:\n",
    "- XXX_SocialDistancing_v1_0_index.shp - the full set of spatial units (polygons) with ease of social distancing index values calculated. The INDEXvalue field provides the index values (0-10), calculated as the mean of the BUILTscore and POPscore field values. A value of 1 is indicative of relative ease of social distancing due to low population density and ample space around buildings. A value of 10 is indicative of high difficulty in maintaining social distancing due to very high population density and very little space around buildings. A no data value (-99) indicates missing data.\n",
    "- XXX_SocialDistancing_v1_0_urban_extents.shp - polygons of the urban extents within which ease of social distancing index values were calculated\n",
    "- XXX_SocialDistancing_v1_0_urban_points.shp - points representing urban centres, within each urban extent. Urban centre names and locations are derived from the GHS Urban Centre Database 2015 v1.2 (Florczyk et al., 2019a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
